# -*- coding: utf-8 -*-
"""CNN1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A5JUlQNxseoPgNYjkLyC5Rb7UJC3Zdol
"""

import os
from google.colab import drive
drive.mount('/content/drive')
project_folder = '/content/drive/My Drive/Colab Notebooks/ARCHER2_RUNS/results' # working folder path
os.chdir(project_folder) # changing the path

import numpy as np
from scipy.ndimage import distance_transform_edt
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import layers, models

field = np.load('field.npy') # n x Ny x Nx x 3
geometry = np.load('geo.npy') # n x Ny x Nx

vx = field[:,:,:,1] # n x Ny x Nx
vy = field[:,:,:,2] # n x Ny x Nx
rho = field[:,:,:,0]

# Input layer
input_layer = layers.Input(shape=(geometry.shape[1], geometry.shape[2], 1))

# Convolutional layers
x = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.Conv2D(64, (3, 3), activation='relu')(x)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.Conv2D(64, (3, 3), activation='relu')(x)

# Flattening the output of the conv layers to feed into the dense layer
x = layers.Flatten()(x)
x = layers.Dense(64, activation='relu')(x)

# Output layers for the x and y components of the velocity
output_x = layers.Dense(vx.shape[1] * vx.shape[2], activation='linear', name='velocity_x')(x)
output_y = layers.Dense(vy.shape[1] * vy.shape[2], activation='linear', name='velocity_y')(x)
output_rho = layers.Dense(rho.shape[1] * rho.shape[2], activation='linear', name='density')(x)

# Create the model
model = models.Model(inputs=input_layer, outputs=[output_x, output_y, output_rho])

model.summary()

model.compile(
    optimizer='adam',
    loss='mean_squared_error',  # Switched from custom_loss_function to mean_squared_error
    metrics={'velocity_x': ['mae'], 'velocity_y': ['mae'], 'density' : ['mae']}
)

Input_data = geometry.reshape((geometry.shape[0], geometry.shape[1], geometry.shape[2], 1))
Vx_data = vx.reshape((vx.shape[0], vx.shape[1] * vx.shape[2]))
Vy_data = vy.reshape((vy.shape[0], vy.shape[1] * vy.shape[2]))
Rho_data = rho.reshape((rho.shape[0], rho.shape[1] * rho.shape[2]))

np.random.seed(42)  # For reproducibility
indices = np.arange(Input_data.shape[0])
np.random.shuffle(indices)

train_size = int(0.8 * len(indices))
train_indices = indices[:train_size]
test_indices = indices[train_size:]

Input_train = Input_data[train_indices]
Input_test = Input_data[test_indices]

Vx_train = Vx_data[train_indices]
Vx_test = Vx_data[test_indices]

Vy_train = Vy_data[train_indices]
Vy_test = Vy_data[test_indices]

Rho_train = Rho_data[train_indices]
Rho_test = Rho_data[test_indices]

early_stopping = EarlyStopping(
   monitor='val_loss',  # Monitors the validation loss
   patience=25,          # Number of epochs with no improvement after which training will be stopped
   verbose=1,           # To print messages when the callback takes action
   mode='min',          # Stops training when the quantity monitored has stopped decreasing
   restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity.
)

history = model.fit(Input_train, {'velocity_x': Vx_train, 'velocity_y': Vy_train, 'density':Rho_train}, epochs=10, batch_size=32, validation_split=0.2)
test_scores = model.evaluate(Input_test, [Vx_test, Vy_test, Rho_test])

predictions = model.predict(Input_test)

def compute_mea(ground_truth,prediction):
  absolute_errors = np.abs(ground_truth - prediction)
  mae = np.mean(absolute_errors)
  return mae

def compute_velocity_magnitude(vx, vy):
    return np.sqrt(vx**2 + vy**2)

mae_v = []
mae_rho = []
mre_v = []
mre_rho = []

for j in range(predictions[0].shape[0]):
  predicted_vx = predictions[0][j].reshape(300, 300)
  predicted_vy = predictions[1][j].reshape(300, 300)
  predicted_velocity_magnitude = compute_velocity_magnitude(predicted_vx,predicted_vy)
  original_velocity_magnitude = compute_velocity_magnitude(Vx_test[j,:].reshape(300, 300) , Vy_test[j,:].reshape(300, 300) )
  predicted_rho = predictions[2][j].reshape(300, 300)
  mae_v.append(compute_mea(original_velocity_magnitude,predicted_velocity_magnitude))
  mae_rho.append(compute_mea(Rho_test[j,:].reshape(300, 300),predicted_rho))


  # Compute MRE for velocity and density, ignoring infinities
  mre_v_values = np.abs(original_velocity_magnitude - predicted_velocity_magnitude) / np.abs(original_velocity_magnitude)
  mre_rho_values = np.abs(Rho_test[j, :].reshape(300, 300) - predicted_rho) / np.abs(Rho_test[j, :].reshape(300, 300))
  mre_v_filtered = mre_v_values[np.isfinite(mre_v_values)]
  mre_rho_filtered = mre_rho_values[np.isfinite(mre_rho_values)]

  mre_v.append(np.mean(mre_v_filtered)*100)
  mre_rho.append(np.mean(mre_rho_filtered)*100)

# MAE values
print(np.mean(mae_v))
print(np.mean(mae_rho))

# MRE values
print(np.mean(mre_v))
print(np.mean(mre_rho))

# Standar deviation
print(np.std(mae_v))
print(np.std(mae_rho))

from scipy.stats import skew, kurtosis
# Skweness
print(skew(mae_v))
print(skew(mae_rho))
# kurtosis
print(kurtosis(mae_v))
print(kurtosis(mae_rho))

import matplotlib.pyplot as plt
import matplotlib as mpl
mpl.rcParams.update({'font.size': 19})


num_bins = 50  # Number of bins for the histogram

# Create a figure and two subplots
plt.figure(figsize=(14, 6))  # Adjusted width to 14 for better spacing

# First subplot for mae_v
plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot
plt.hist(mae_v, bins=num_bins, color='skyblue', edgecolor='black')
plt.xlabel('MAE - Velocity')
plt.ylabel('Frequency')

# Second subplot for mae_rho
plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot
plt.hist(mae_rho, bins=num_bins, color='salmon', edgecolor='black')
plt.xlabel('MAE - Density')
plt.ylabel('Frequency')

# Display the plots
plt.tight_layout()  # Adjusts spacing to prevent overlap
plt.show()

index = 1
original_velocity_magnitude = compute_velocity_magnitude(Vx_test[index,:].reshape(300, 300) , Vy_test[index,:].reshape(300, 300) )
predicted_vx = predictions[0][index].reshape(300, 300)  # Reshape to original dimensions
predicted_vy = predictions[1][index].reshape(300, 300)
predicted_rho = predictions[2][index].reshape(300, 300)

predicted_velocity_magnitude = compute_velocity_magnitude(predicted_vx,predicted_vy)

import matplotlib.pyplot as plt
import numpy as np
import matplotlib as mpl

# Increase default font size for all plot elements
mpl.rcParams.update({'font.size': 20})


fig, axs = plt.subplots(1, 3, figsize=(18, 6))  # 1 row, 3 columns

# Original Velocity Magnitude
im1 = axs[0].imshow(Rho_test[index,:].reshape(300, 300), cmap='viridis',origin='lower')
axs[0].set_title('Original')
axs[0].axis('off')  # Hide axes for better visualization

# Predicted Velocity Magnitude
im2 = axs[1].imshow(predicted_rho, cmap='viridis',origin='lower')
axs[1].set_title('Predicted ')
axs[1].axis('off')

# Difference in Velocity Magnitude
im3 = axs[2].imshow(np.abs(predicted_rho- Rho_test[index,:].reshape(300, 300)), cmap='viridis',origin='lower')
axs[2].set_title('Difference')
axs[2].axis('off')

# Place a colorbar below the subplots, make it larger using 'fraction' and 'pad'
cbar_ax = fig.add_axes([0.15, -0.05, 0.7, 0.05])  # x-position, y-position, width, height
fig.colorbar(im1, cax=cbar_ax, orientation='horizontal', fraction=0.2, pad=0.4,label='Density')

plt.tight_layout()